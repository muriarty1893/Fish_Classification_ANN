{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2170465,
          "sourceType": "datasetVersion",
          "datasetId": 1165452
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Fish_Classification_ANN",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muriarty1893/Fish_Classification_ANN/blob/master_alfa/Fish_Classification_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "crowww_a_large_scale_fish_dataset_path = kagglehub.dataset_download('crowww/a-large-scale-fish-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "9VeIOccbyx6c"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block\" style=\"background-color: #00b7eb;\">\n",
        "  <span style=\"color:#2c3e50; font-weight: bold; font-size: 26px;\"> 🎣 Balık Görüntü Sınıflandırması: Derin Öğrenme (ANN) Yaklaşımı</span>\n",
        "</div>"
      ],
      "metadata": {
        "id": "EpfJMQXbyx6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Veri Seti Hakkında Bilgiler:</h3>\n",
        "<ul style=\"background-color: #e3f2fd; padding: 15px; border-radius: 10px;\">\n",
        "        Bu veri seti, İzmir'deki bir süpermarketten toplanan 9 farklı deniz ürünü türüne ait görüntüler içermektedir. Veri seti, İzmir Ekonomi Üniversitesi ve bir sanayi kuruluşunun iş birliğiyle yürütülen üniversite-sanayi ortaklık projesi kapsamında toplanmış ve bu çalışma ASYU 2020'de yayınlanmıştır. <br>Veri seti, gilt head bream, red sea bream, sea bass, red mullet, horse mackerel, black sea sprat, striped red mullet, trout ve shrimp türlerine ait görüntü örneklerinden oluşmaktadır.\n",
        "</ul>"
      ],
      "metadata": {
        "id": "LilB4Ab5yx6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Proje Yaklaşımı:</h3>\n",
        "<ul style=\"background-color: #e3f2fd; padding: 15px; border-radius: 10px;\">\n",
        "  Bu projede, balık türlerinin sınıflandırılması amaçlanmaktadır. Genelde bu tür sınıflandırma görevleri için Convolutional Neural Network (CNN) kullanılır. CNN'ler, en kaba haliyle iki ana bölümden oluşur:\n",
        "    <br><li>Özellik Çıkarımı (görüntüdeki nesneleri birbirinden ayırt edebilmek için anlamlı özellikler oluşturma)</li>\n",
        "    <li>Klasik Sinir Ağı Katmanı (elde edilen bu özellikleri kullanarak sınıflandırma yapma).</li><br>\n",
        "   📌 Ancak bu projede, CNN kullanmak yerine yalnızca Yapay Sinir Ağı (ANN) kullanarak sınıflandırma yapılmaktadır. Özellik çıkarımı aşaması olmadan, görüntüler doğrudan ANN'e verilmiş ve balık türlerinin doğru şekilde sınıflandırılması sağlanmıştır.\n",
        "</ul>"
      ],
      "metadata": {
        "id": "btK7IeCIyx6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Projenin  Amacı:</h3>\n",
        "<ul style=\"background-color: #e3f2fd; padding: 15px; border-radius: 10px;\">\n",
        "Bu projenin amacı, ANN kullanarak balık türlerini doğru şekilde sınıflandırmak ve modelin genelleme kabiliyetini artırmaktır. Genelleme kabiliyeti, modelin daha önce görmediği yeni verileri doğru şekilde tahmin edebilme yeteneğidir. Ancak, aşırı öğrenme (overfitting) bu kabiliyeti engelleyebilir. Bu sorunu aşmak için early stopping ve dropout gibi yöntemler kullanılmıştır. Ek olarak, hiperparametre optimizasyonu yapılmıştır.\n",
        "</ul>"
      ],
      "metadata": {
        "id": "p_UrwQOtyx6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a class=\"anchor\" id=\"import\"></a>\n",
        "\n",
        "## <span style=\"color:#FA8072\">  Kütüphanelerin Import Edilmesi </span> <a class=\"anchor\" id=\"import_libraries\"></a>"
      ],
      "metadata": {
        "id": "zk41xoryyx6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T08:41:39.287535Z",
          "iopub.execute_input": "2024-10-24T08:41:39.288649Z",
          "iopub.status.idle": "2024-10-24T08:41:53.745607Z",
          "shell.execute_reply.started": "2024-10-24T08:41:39.288596Z",
          "shell.execute_reply": "2024-10-24T08:41:53.744115Z"
        },
        "trusted": true,
        "id": "8aLMLNxDyx6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import os\n",
        "import collections\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Rescaling, Input, Dense, Dropout, BatchNormalization, Flatten\n",
        "from tensorflow.keras.initializers import RandomNormal, RandomUniform, GlorotUniform, GlorotNormal, HeNormal\n",
        "from keras.optimizers.schedules import ExponentialDecay\n",
        "from keras_tuner import RandomSearch, GridSearch, BayesianOptimization\n",
        "from keras_tuner.engine.hyperparameters import HyperParameters"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-10-24T08:41:53.748491Z",
          "iopub.execute_input": "2024-10-24T08:41:53.749008Z",
          "iopub.status.idle": "2024-10-24T08:42:04.227349Z",
          "shell.execute_reply.started": "2024-10-24T08:41:53.748959Z",
          "shell.execute_reply": "2024-10-24T08:42:04.22626Z"
        },
        "trusted": true,
        "id": "OzIuf1cLyx6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a class=\"anchor\" id=\"read\"></a>\n",
        "\n",
        "## <span style=\"color:#FA8072\">  Veri Setini Okuma </span> <a class=\"anchor\" id=\"load_data\"></a>"
      ],
      "metadata": {
        "id": "r1M14xtoyx6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = []\n",
        "path = []\n",
        "fish_dir = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'\n",
        "\n",
        "for dir_name, _, filenames in os.walk(fish_dir):\n",
        "    for filename in filenames:\n",
        "        if os.path.splitext(filename)[-1] == '.png':\n",
        "            if dir_name.split()[-1] != 'GT':\n",
        "                label.append(os.path.split(dir_name)[-1])\n",
        "                path.append(os.path.join(dir_name, filename))\n",
        "\n",
        "data = pd.DataFrame(columns=['path', 'label'])\n",
        "data['path'] = path\n",
        "data['label'] = label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T08:42:04.229221Z",
          "iopub.execute_input": "2024-10-24T08:42:04.230082Z",
          "iopub.status.idle": "2024-10-24T08:42:06.681213Z",
          "shell.execute_reply.started": "2024-10-24T08:42:04.230024Z",
          "shell.execute_reply": "2024-10-24T08:42:06.679997Z"
        },
        "trusted": true,
        "id": "-PMpbQFCyx6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "Bu kod, balık fotoğraflarının dosya yollarını ve ilgili sınıf etiketlerini belirler. .png uzantılı dosyalar ve bu dosyaların etiketleri, listelere eklenir. Ardından, bu veriler path ve label sütunlarına sahip bir pandas DataFrame'e kaydedilir. Böylece, balık fotoğrafları etiketlenmiş ve model eğitimi veya analiz yapmak için hazır hale getirilmiş olur.\n",
        "    <br><br> Özetle:  Bu kodun ile balık fotoğraflarının dosya yollarını ve etiketlerini içeren bir pandas DataFrame oluşturulmuştur.\n",
        "</p>"
      ],
      "metadata": {
        "id": "UOJoyjQuyx6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a class=\"anchor\" id=\"read\"></a>\n",
        "\n",
        "## <span style=\"color:#FA8072\">  Keşifsel Veri Analizi </span> <a class=\"anchor\" id=\"load_data\"></a>"
      ],
      "metadata": {
        "id": "usLu7n2yyx6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data adlı veri çerçevesinin kaç satır ve kaç sütundan oluştuğunu ekrana yazdırır\n",
        "print(f\" Count of Rows : {data.shape[0]} \\n Count of Columns : {data.shape[1]} \")\n",
        "\n",
        "# data.shape[0]: Veri çerçevesindeki toplam satır sayısını(9000) ifade eder\n",
        "# data.shape[1]: Veri çerçevesindeki toplam sütun sayısını(2) ifade eder"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T08:42:06.682889Z",
          "iopub.execute_input": "2024-10-24T08:42:06.683338Z",
          "iopub.status.idle": "2024-10-24T08:42:06.689751Z",
          "shell.execute_reply.started": "2024-10-24T08:42:06.683294Z",
          "shell.execute_reply": "2024-10-24T08:42:06.688603Z"
        },
        "trusted": true,
        "id": "LTlP2s0syx6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Örnek veri kontrolü ve veri inceleme\n",
        "print(data.head())\n",
        "print(f\"Toplam Fotoğraf Sayısı: {len(data)}\")\n",
        "print(f\"Sınıf Dağılımı:\\n{data['label'].value_counts()}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T08:42:06.693093Z",
          "iopub.execute_input": "2024-10-24T08:42:06.693561Z",
          "iopub.status.idle": "2024-10-24T08:42:06.721696Z",
          "shell.execute_reply.started": "2024-10-24T08:42:06.693518Z",
          "shell.execute_reply": "2024-10-24T08:42:06.720477Z"
        },
        "trusted": true,
        "id": "s3Wkpk2Jyx6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "Veri setimizde toplam 9 farklı balık türü bulunmaktadır ve her türden 1000 fotoğraf vardır. <br> Bu, her sınıfın eşit sayıda gözleme sahip olduğunu ve dengeli bir veri seti olduğunu gösterir.\n",
        "    <br>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "M-X7flhKyx6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bazı örnek görüntüleri görselleştirme\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    img = cv2.imread(data['path'][i])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img)\n",
        "    plt.title(data['label'][i])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T08:42:06.723264Z",
          "iopub.execute_input": "2024-10-24T08:42:06.72367Z",
          "iopub.status.idle": "2024-10-24T08:42:08.582628Z",
          "shell.execute_reply.started": "2024-10-24T08:42:06.723627Z",
          "shell.execute_reply": "2024-10-24T08:42:08.581188Z"
        },
        "trusted": true,
        "id": "ZK81nd4myx6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a class=\"anchor\" id=\"read\"></a>\n",
        "\n",
        "## <span style=\"color:#FA8072\">  Veri Setini Ayırma </span> <a class=\"anchor\" id=\"load_data\"></a>"
      ],
      "metadata": {
        "id": "8WmF9krVyx6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Veriyi eğitim ve test veri setlerine ayırır.\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, shuffle=True, random_state=53)\n",
        "\n",
        "print(train_data.shape)  # Eğitim veri setinin satır ve sütun sayısını gösterir.\n",
        "print(test_data.shape)   # Test veri setinin satır ve sütun sayısını gösterir."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T08:42:08.584278Z",
          "iopub.execute_input": "2024-10-24T08:42:08.584704Z",
          "iopub.status.idle": "2024-10-24T08:42:08.597778Z",
          "shell.execute_reply.started": "2024-10-24T08:42:08.58466Z",
          "shell.execute_reply": "2024-10-24T08:42:08.596605Z"
        },
        "trusted": true,
        "id": "5SDv71uPyx6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "  <span style=\"font-weight: bold;\"></span>  Veri setimiz, ilk olarak <span style=\"font-weight: bold;\">train_test_split</span> kullanılarak test_size=0.2, %80 eğitim ve %20 test olarak ikiye bölünür. Daha sonra <span style=\"font-weight: bold;\"> ImageDataGenerator</span> kullanarak, eğitim verisinin %20'sini doğrulama (validation) seti olarak ayırıyoruz (validation_split=0.2). Bu sayede:<br><br>\n",
        "  • <span style=\"font-weight: bold;\">Eğitim Seti (%64):</span>Modelin öğrenmesi için kullanılır. Model, bu verilerden sınıflar arasındaki ilişkileri öğrenir ve kendini eğitir.<br><br>\n",
        "  • <span style=\"font-weight: bold;\">Doğrulama Seti (%16):</span>Eğitim sırasında modelin performansını izleriz. Her eğitim döngüsünde modelin ne kadar iyi öğrendiğini gösterir ve aşırı öğrenme olup olmadığını kontrol ederiz. Doğrulama seti olmadan, modelin ezber yapıp yapmadığını fark edemez ve bu da yeni verilerde kötü sonuçlara yol açabilir.<br><br>\n",
        "  • <span style=\"font-weight: bold;\">Test Seti (%20):</span>Eğitim tamamlandıktan sonra modelin yeni ve daha önce görmediği veriler üzerindeki başarısını ölçmek için kullanılır. Bu set, modelin gerçek dünyadaki performansını değerlendirmemizi sağlar.<br><br>\n",
        "</p>"
      ],
      "metadata": {
        "id": "Gj-TvgEEyx6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\"> <br>\n",
        "  • <span style=\"font-weight: bold;\">random_state=53:</span>Her çalıştırmada aynı veri bölmesini sağlar, böylece sonuçlar tutarlı olur ve her defasında aynı eğitim ve test setleri elde edilir.<br>Sayının kendisi özel bir anlam taşımaz; başka bir sayı da kullanılabilir.<br><br>\n",
        "  • <span style=\"font-weight: bold;\">shuffle=True:</span>Verileri rastgele karıştırır, böylece modelin sıralı verilere bağlı kalması engellenir ve bu da modelin genelleme kabiliyetini artırır. Verilerin homojen dağılımını sağlar.<br><br>\n",
        "\n",
        "</p>"
      ],
      "metadata": {
        "id": "FsB9SO06yx6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "       🟧 Eğitim ve doğrulama setlerini ayırmak için alternatif olarak, veri setini manuel bir şekilde üç bölüme (eğitim, doğrulama, test) ayırabilirdik. Ancak bu yöntem süreci daha karmaşık hale getirebilir. Bunun yerine, ImageDataGenerator kullanarak validation_split parametresiyle doğrulama setini otomatik olarak ayırmak, daha pratik ve daha hızlı bir yöntemdir. Bu nedenle bu yöntemi tercih ediyorum.\n",
        "</p>"
      ],
      "metadata": {
        "id": "VmJYKVU2yx6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a class=\"anchor\" id=\"read\"></a>\n",
        "\n",
        "## <span style=\"color:#FA8072\">  Ön İşleme ve Veri Akışı Oluşturma </span> <a class=\"anchor\" id=\"load_data\"></a>"
      ],
      "metadata": {
        "id": "b5EUYC_6yx6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageDataGenerator Nesnelerinin Oluşturulması(train_generator, test_generator)\n",
        "train_generator = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n",
        "\n",
        "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T08:42:08.599248Z",
          "iopub.execute_input": "2024-10-24T08:42:08.599644Z",
          "iopub.status.idle": "2024-10-24T08:42:08.608467Z",
          "shell.execute_reply.started": "2024-10-24T08:42:08.599601Z",
          "shell.execute_reply": "2024-10-24T08:42:08.60724Z"
        },
        "trusted": true,
        "id": "J3JL6oyuyx6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "   Bu kod ile iki <span style=\"font-weight: bold;\">ImageDataGenerator nesnesi</span> oluşturuyoruz: train_generator eğitim ve doğrulama seti için, test_generator ise test verileri için kullanılıyor.<br> Bu nesneler, verilerin normalizasyonunu yaparak modelin anlayabileceği formata dönüştürür. <span style=\"font-weight: bold;\">preprocessing_function=preprocess_input parametresi</span>, verilerin normalleştirilmesini sağlar ve bu sayede veriler modelin öğrenmesi için uygun hale gelir.<br>\n",
        "    Ayrıca, validation_split=0.2 kullanarak, eğitim verisinin %20'sini doğrulama seti olarak ayırıyoruz. Böylece, aynı train_data seti içinden hem eğitim hem de doğrulama setleri oluşturulmuş oluyor.<br>\n",
        "</p>"
      ],
      "metadata": {
        "id": "1uwSGFR4yx6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<ul style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "  <span style=\"font-weight: bold;\">🟧 Veri Artırımı (Data Augmentation)</span><br> Bu noktada, veriler üzerinde herhangi bir veri artırımı (data augmentation) yapılmadı. Sadece normalizasyon işlemi yapıldı.<br>\n",
        "      • Eğer veri artırımı yapmak isteseydik, ImageDataGenerator'ın rotation_range, width_shift_range, height_shift_range gibi ek parametrelerini kullanabilirdik.⬇️<br><br>\n",
        "\n",
        "</ul>"
      ],
      "metadata": {
        "id": "uLzuDQFtyx6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_generator = ImageDataGenerator(\n",
        "#    preprocessing_function=preprocess_input,\n",
        "#    validation_split=0.2,\n",
        "#    rotation_range=30,          # Döndürme\n",
        "#    width_shift_range=0.2,      # Yatay kaydırma\n",
        "#    height_shift_range=0.2,     # Dikey kaydırma\n",
        "#    zoom_range=0.2,             # Yakınlaştırma\n",
        "#    horizontal_flip=True        # Yatay çevirme\n",
        "#)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T08:42:08.610464Z",
          "iopub.execute_input": "2024-10-24T08:42:08.610947Z",
          "iopub.status.idle": "2024-10-24T08:42:08.620505Z",
          "shell.execute_reply.started": "2024-10-24T08:42:08.610895Z",
          "shell.execute_reply": "2024-10-24T08:42:08.61898Z"
        },
        "trusted": true,
        "id": "DARo_-wzyx6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veri Akışlarının Oluşturulması (flow_from_dataframe)\n",
        "x_train = train_generator.flow_from_dataframe(dataframe=train_data, x_col='path', y_col='label', target_size=(224, 224), color_mode='rgb', class_mode='categorical', batch_size=32, shuffle=True, seed=53, subset='training')\n",
        "\n",
        "x_val = train_generator.flow_from_dataframe(dataframe=train_data, x_col='path', y_col='label', target_size=(224, 224), color_mode='rgb', class_mode='categorical', batch_size=32, shuffle=True, seed=53, subset='validation' )\n",
        "\n",
        "x_test = test_generator.flow_from_dataframe(dataframe=test_data, x_col='path', y_col='label', target_size=(224, 224), color_mode='rgb', class_mode='categorical', batch_size=32, shuffle=False )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T08:42:08.622576Z",
          "iopub.execute_input": "2024-10-24T08:42:08.623049Z",
          "iopub.status.idle": "2024-10-24T08:42:16.463318Z",
          "shell.execute_reply.started": "2024-10-24T08:42:08.623005Z",
          "shell.execute_reply": "2024-10-24T08:42:16.461954Z"
        },
        "trusted": true,
        "id": "ntauk-k0yx6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "  Bu kod, train_generator ve test_generator nesneleri ile belirli parametreler kullanarak:<br><br>\n",
        "  •  <span style=\"font-weight: bold;\">x_train:</span> Modelin eğitim sürecinde kullanacağı verilerin akışını sağlar.<br><br>\n",
        "  •  <span style=\"font-weight: bold;\">x_val:</span> Doğrulama seti olarak ayrılmış verilerin akışını sağlar.<br><br>\n",
        "  •  <span style=\"font-weight: bold;\">x_test:</span> Modelin test seti üzerinde performansını değerlendirebilmesi için veri akışını oluşturur.<br><br>\n",
        "   📌 Bu akışlar, verilerin modelin anlayabileceği ve işleyebileceği uygun formata getirilmesini sağlar.\n",
        "</p>"
      ],
      "metadata": {
        "id": "XgAWDNyhyx6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "  Veri akışları oluşturulurken kullanılan parametreleri inceleyelim. Parametreler şu şekildedir:<br><br>\n",
        "  •  <span style=\"font-weight: bold;\">target_size=(224, 224):</span> Görüntülerin boyutunu 224x224 piksel olarak yeniden boyutlandırır.<br><br>\n",
        "  •  <span style=\"font-weight: bold;\">color_mode='rgb':</span> Görüntüleri RGB formatında işler.<br><br>\n",
        "    </p>"
      ],
      "metadata": {
        "id": "rFZqY1s-yx6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "  Veri setimizdeki hedef değişkenler, yani etiketler, kategorik ve çok sınıflı olarak düzenlenmiştir. Modelin bu sınıfları öğrenebilmesi için etiketlerin sayısal bir formata dönüştürülmesi gerekmektedir. Bu noktada \"class_mode\" parametresi devreye girer ve çok sınıflı etiketler için iki seçenek sunar: categorical ve sparse:<br><br>\n",
        "   •  <span style=\"font-weight: bold;\">class_mode='categorical':</span> One-hot encoding formatında sınıf etiketlerini temsil eder. Yani her sınıf, yalnızca o sınıfı belirten bir vektörle ifade edilir. Örneğin, 3 sınıf varsa bu sınıflar [1, 0, 0], [0, 1, 0], [0, 0, 1] şeklinde vektör formunda temsil edilir. Bu durumda kayıp fonksiyonu olarak categorical_crossentropy kullanmanız gerekmektedir. <br><br>  Diğer seçeneğimiz;  <span style=\"font-weight: bold;\">class_mode='sparse':</span> Sınıflar tamsayılar (integer) olarak temsil edilir. Her sınıf, 0, 1, 2, ... şeklinde sayısal bir değere karşılık gelir. Örneğin, 5 sınıfınız varsa bu sınıflar 0, 1, 2, 3, 4 olarak tanımlanır. Kayıp fonksiyonu olarak sparse_categorical_crossentropy kullanmanız gerekir. Bu yöntem, bellekte yerden tasarruf sağlar ve hesaplama hızını artırır. <br><br>\n",
        "    📌 \"Bu projede, class_mode='categorical' seçeneğini kullanarak modelin etiketlerini one-hot encoding formatına dönüştürdüm. Buna bağlı olarak, modelin derlenmesi aşamasında categorical_crossentropy kayıp fonksiyonunu tercih ettim.\"<br><br>\n",
        "    </p>"
      ],
      "metadata": {
        "id": "SbMT_79Nyx6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "     •  <span style=\"font-weight: bold;\">batch_size=32:</span>Model, verileri 32'lik gruplar (batch'ler) halinde işler. Yani, her adımda model 32 görüntüyü alıp bu görüntüler üzerinde eğitimi gerçekleştirir. Bu yöntemi kullanmamızın sebebi, Tüm veri setini aynı anda işlemek büyük bir bellek gerektirir. Bu yüzden verileri küçük partiler (batch'ler) halinde işlemek belleği daha verimli kullanmayı sağlar.<br><br>\n",
        "Peki batch_size değerini nasıl belirlemeliyiz? 🧐<br><br>\n",
        "     <span style=\"font-weight: bold;\">Küçük batch_size (örneğin 16):</span> Modelin daha iyi öğrenmesini sağlayabilir, ancak eğitim süresi uzar.<br><br>\n",
        "      <span style=\"font-weight: bold;\">Büyük batch_size (örneğin 128 veya daha fazla):</span>  Daha hızlı eğitim sağlar, ancak modelin öğrenme kapasitesi azalabilir ve aşırı öğrenme (overfitting) riski artar.<br><br>\n",
        "      <span style=\"font-weight: bold;\">Denge Sağlamak:</span> Genellikle 32 veya 64 gibi dengeli bir değer, eğitim süresi ve performans açısından tercih edilir.<br><br>\n",
        "    </p>"
      ],
      "metadata": {
        "id": "f6Rt0Zl_yx6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "    •  <span style=\"font-weight: bold;\">shuffle=True/False:</span> <br><br>\n",
        "     <span style=\"font-weight: bold;\">shuffle=True:</span> Eğitim ve doğrulama verilerini rastgele karıştırır. Bu, verilerin homojen bir şekilde dağılmasını sağlar ve modelin her sınıfı eşit derecede öğrenmesine yardımcı olur, ezberleme riskini azaltır.<br><br>\n",
        "    <span style=\"font-weight: bold;\">shuffle=False:</span> Test verileri karıştırılmaz. Bu, modelin gerçek performansını objektif bir şekilde değerlendirmemizi sağlar.\n",
        "    </p>"
      ],
      "metadata": {
        "id": "lkXYOxElyx6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " <p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "    •  <span style=\"font-weight: bold;\">seed=53:</span> Rastgele işlemlerin tekrarlanabilirliğini sağlamak amacıyla kullanılır, yani her çalıştırmada aynı başlangıç koşullarını elde ederiz. Birkaç örnek vermek gerekirse;<br><br>\n",
        "    <span style=\"font-weight: bold;\">Verilerin Karıştırılması (shuffle=True):</span> Eğitim ve doğrulama verilerini karıştırmak için shuffle=True kullanıldığında, veriler her çalıştırmada rastgele olarak farklı sıralarda olabilir. Ancak seed=42 kullanarak bu rastgeleliği sabitlersek, her çalıştırmada aynı karıştırma işlemi uygulanır ve tutarlılık sağlanır.<br><br>\n",
        "     <span style=\"font-weight: bold;\">Başlangıç Ağırlıklarının Sabitlenmesi:</span> Modelin başlangıçtaki ağırlıkları da rastgele belirlenir. Seed kullanarak bu başlangıç ağırlıklarını sabitleriz. Bu, her çalıştırmada modelin aynı başlangıç koşullarına sahip olmasını ve tutarlı sonuçlar elde edilmesini mümkün kılar.<br><br>\n",
        "Eğitim sürecinde ağırlıklar her epoch'ta optimize edilerek modelin performansı iyileştirilir. <br><br>\n",
        "   📌<span style=\"font-weight: bold;\">Ağırlıkların önemi:</span> Öğrenme süreci, modelin hata oranını (loss) düşürmeye çalışmasıdır. Model, her iterasyonda (epoch) ağırlıkları ayarlayarak, bu hatayı en aza indirmeyi hedefler. Yani, öğrenme süreci boyunca amaç, ağırlıkların en uygun değerlerini bularak modelin performansını artırmaktır.\n",
        "    <br><br>    \n",
        "    🟧 <span style=\"font-weight: bold;\">Seed'e benzer bir random_state kullanmıştık, peki bunların farkı nedir?🧐</span><br><br>\n",
        "     <span style=\"font-weight: bold;\">seed=53:</span> Genellikle rastgele işlemler (örneğin, verilerin karıştırılması, ağırlıkların rastgele başlatılması) sırasında kullanılır.<br><br>\n",
        "       <span style=\"font-weight: bold;\">random_state=53:</span> Daha çok veri setinin bölünmesi gibi işlemler sırasında kullanılır ve veri bölünmesinin her seferinde aynı şekilde yapılmasını sağlar.<br><br>\n",
        "--ikisi de rastgelelik faktörünü sabitleyerek sürecin tekrar edilebilir olmasını sağlar.<br>\n",
        "    \n",
        "  </p>"
      ],
      "metadata": {
        "id": "59CN6djoyx6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " <p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "    •  <span style=\"font-weight: bold;\">subset='training'/'validation':</span>\n",
        "train_generator nesnesini kullanarak eğitim (training) ve doğrulama (validation) verilerini ayırır.\n",
        "    </p>"
      ],
      "metadata": {
        "id": "t1JwOWd3yx6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Sınıf dağılımını yazdırmak için fonksiyon\n",
        "def print_class_distribution(dataset, dataset_name):\n",
        "    train_labels = dataset.classes\n",
        "    class_counts = collections.Counter(train_labels)\n",
        "    print(f\"{dataset_name} Class Distribution: {class_counts}\")\n",
        "\n",
        "    labels_map = {v: k for k, v in dataset.class_indices.items()}\n",
        "    for class_index, count in class_counts.items():\n",
        "        print(f\"Class '{labels_map[class_index]}': {count}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T08:42:16.464969Z",
          "iopub.execute_input": "2024-10-24T08:42:16.465491Z",
          "iopub.status.idle": "2024-10-24T08:42:16.473772Z",
          "shell.execute_reply.started": "2024-10-24T08:42:16.465434Z",
          "shell.execute_reply": "2024-10-24T08:42:16.472238Z"
        },
        "trusted": true,
        "id": "RmnhbKBEyx6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim, doğrulama ve test veri setlerinin sınıf dağılımı\n",
        "print_class_distribution(x_train, \"Training\")\n",
        "print_class_distribution(x_val, \"Validation\")\n",
        "print_class_distribution(x_test, \"Test\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T08:42:16.475604Z",
          "iopub.execute_input": "2024-10-24T08:42:16.476215Z",
          "iopub.status.idle": "2024-10-24T08:42:16.486917Z",
          "shell.execute_reply.started": "2024-10-24T08:42:16.476156Z",
          "shell.execute_reply": "2024-10-24T08:42:16.485512Z"
        },
        "trusted": true,
        "id": "ZKRyHONbyx6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(x_train.class_indices)\n",
        "display(x_val.class_indices)\n",
        "display(x_test.class_indices)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T08:42:16.48879Z",
          "iopub.execute_input": "2024-10-24T08:42:16.489323Z",
          "iopub.status.idle": "2024-10-24T08:42:16.507242Z",
          "shell.execute_reply.started": "2024-10-24T08:42:16.489269Z",
          "shell.execute_reply": "2024-10-24T08:42:16.505964Z"
        },
        "trusted": true,
        "id": "Vb9j3L4Dyx6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " 📌 Veri akışlarını oluştururken class_mode='categorical' seçeneğini belirlemiştik. <br>Bu seçeneğin anlamı, hedef değişkenlerin sayısal bir formda, yani kategorik bir vektör şeklinde temsil edilmesidir. <br>Bu sayede model, her sınıfı sayısal bir formata dönüştürerek öğrenebilir.\n",
        "    <br><br>Örneğin:<br><br>\n",
        "  •  'Black Sea Sprat' → [1, 0, 0, 0, 0, 0, 0, 0, 0] (Sınıf 0).<br><br>\n",
        "  •  'Red Mullet' → [0, 1, 0, 0, 0, 0, 0, 0, 0] (Sınıf 1)<br><br>\n",
        "    •  'Red Mullet' → [0, 0, 1, 0, 0, 0, 0, 0, 0] (Sınıf 2)<br><br>\n",
        "    •  ...<br><br>\n",
        "    •  'Red Mullet' → [0, 0, 0, 1, 0, 0, 0, 0, 0] (Sınıf 3)<br><br>\n",
        "    Görüldüğü üzere, her sınıf bir vektörde yalnızca bir pozisyonda 1 değeri alarak ifade edilirken diğer pozisyonlarda 0 yer alır.\n",
        "    </p>"
      ],
      "metadata": {
        "id": "xPLxk3bhyx6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a class=\"anchor\" id=\"read\"></a>\n",
        "\n",
        "## <span style=\"color:#FA8072\"> Modelin Oluşturulması (ANN) </span> <a class=\"anchor\" id=\"load_data\"></a>\n"
      ],
      "metadata": {
        "id": "YRIruwYYyx6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelin Oluşturulması (ANN)\n",
        "def create_model(optimizer='adam', dropout_rate=0.2):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # 1. Normalizasyon (Rescaling)\n",
        "        tf.keras.layers.Rescaling(1./255),\n",
        "\n",
        "        # 2. Giriş Katmanı (Flatten)\n",
        "        tf.keras.layers.Flatten(input_shape=(224, 224, 3)),\n",
        "\n",
        "        # 3. İlk Gizli Katman\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "\n",
        "        # 4. İkinci Gizli Katman\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "\n",
        "        # 5. Üçüncü Gizli Katman\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        #tf.keras.layers.Dropout(dropout_rate),\n",
        "\n",
        "        # 6. Çıkış Katmanı\n",
        "        tf.keras.layers.Dense(9, activation='softmax')\n",
        "    ])\n",
        "\n",
        "     # 7. Modelin Derlenmesi\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T09:35:21.034067Z",
          "iopub.execute_input": "2024-10-24T09:35:21.0345Z",
          "iopub.status.idle": "2024-10-24T09:35:21.044582Z",
          "shell.execute_reply.started": "2024-10-24T09:35:21.03446Z",
          "shell.execute_reply": "2024-10-24T09:35:21.043356Z"
        },
        "trusted": true,
        "id": "wtCNPj4Syx6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3># 1. Normalizasyon (Rescaling)</h3>\n",
        "<ul style=\"background-color:#FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "        Bu katman, görüntü verilerindeki piksel değerlerini 0-255 aralığından [0, 1] aralığına ölçeklendirir. Bu işlem, modelin her piksele eşit şekilde yaklaşmasını sağlar ve bazı piksellere gereksiz yere fazla önem verilmesini önler. Böylece daha tutarlı ve dengeli bir öğrenme elde edilir. Ayrıca, daha küçük ve tutarlı değerler, modelin ağırlıkları daha kolay güncellemesine olanak tanır ve eğitim sürecinin daha hızlı ve verimli olmasına katkıda bulunur.<br><br>\n",
        "   📌 Burada önemli bir nokta, ölçeklendirme işleminin yalnızca piksel değerlerini değiştirdiğidir; yani görüntünün şekli veya içeriği değişmez. Piksel değerleri 0-255 aralığından [0, 1] aralığına çekilse de, görüntünün yapısı (örneğin nesnelerin şekilleri ve renklerin düzeni) bozulmaz. Bu nedenle, görüntünün bilgisi korunur; sadece verilerin ifade edildiği aralık değiştirilir.\n",
        "</ul>"
      ],
      "metadata": {
        "id": "bkzZ_Z2myx6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3># 2. Giriş Katmanı (Flatten)</h3>\n",
        "<ul style=\"background-color:#FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "    tf.keras.layers.Flatten(input_shape=(224, 224, 3)) katmanı, modelin giriş olarak aldığı 224x224 boyutunda ve 3 renk kanalına (RGB) sahip görüntüyü tek boyutlu bir diziye dönüştürür.<br><br>\n",
        "    Nasıl Çalışır?🧐<br><br>\n",
        "    224x224 boyutundaki bir görüntü, her piksel için kırmızı, yeşil ve mavi (RGB) olmak üzere 3 renk bileşenine sahiptir.<br>\n",
        "Flatten katmanı, bu çok boyutlu (224, 224, 3) yapıdaki görüntüyü tek bir uzun vektör haline getirir. Yani, toplamda 224 * 224 * 3 = 150,528 değeri olan düz bir dizi oluşturur.<br><br>\n",
        "  📌 Amaç, flatten katmanı, çok boyutlu görüntü verisini düzleştirerek(düz bir dizi) modelin diğer katmanlarında kullanılabilecek bir formata dönüştürür.\n",
        "</ul>"
      ],
      "metadata": {
        "id": "Jufo2OHFyx6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3># 3. İlk Gizli Katman</h3>\n",
        "<ul style=\"background-color:#FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "  \"tf.keras.layers.Dense(256, activation='relu') \"<br>\n",
        "Bu kod, bir yoğun (dense) katman oluşturur. İşte bu katmanın ana bileşenleri:<br><br>\n",
        "    •  <span style=\"font-weight: bold;\">Nöron Sayısı (256):</span> Bu katman 256 nörona sahiptir ve her nöron, önceki katmandaki tüm nöronlara bağlıdır.<br><br>\n",
        "    •  <span style=\"font-weight: bold;\"> Aktivasyon Fonksiyonu (ReLU):</span> activation='relu' ifadesi, ReLU aktivasyon fonksiyonunun kullanıldığını gösterir. ReLU, pozitif giriş değerlerini olduğu gibi bırakırken, negatif girişleri sıfıra eşitler. Bu, modelin doğrusal olmayan ilişkileri öğrenmesine yardımcı olur ve derin öğrenmede sıklıkla kullanılır. Özellikle gizli katmanlarda ReLU ve türevleri, gradyan kaybolma sorununu azaltmak için tercih edilir.<br><br>\n",
        "   📌  Gradyan kaybolma sorunu, eğitim sürecinde geri yayılım algoritması kullanılarak ağırlıkların güncellenmesi sırasında gradyanların katmanlar ilerledikçe küçülerek neredeyse sıfır olması durumudur. Bu durum, alt katmanların ağırlıklarının güncellenememesine ve modelin eğitiminde duraklamaya yol açar.<br><br>\n",
        "     •  <span style=\"font-weight: bold;\"> Bias Başlatma:</span> Varsayılan olarak, bias değerleri sıfır (bias_initializer='zeros') ile başlatılır. Bu, nöronların başlangıçta nötr olmasını sağlar ve eğitimi dengeler.<br><br>\n",
        "     •  <span style=\"font-weight: bold;\"> Ağırlık Başlatma (He Normal):</span> Varsayılan olarak he_normal yöntemi kullanılır. Bu yöntem, özellikle ReLU gibi aktivasyon fonksiyonları için uygundur ve ağırlıkları ortalama 0 ve belirli bir standart sapmaya sahip bir normal dağılımdan rastgele seçer. Bu sayede model dengeli ve hızlı öğrenebilir.<br><br><br>\n",
        "    •   <span style=\"font-weight: bold;\">Batch Normalization:</span> Her katmandan çıkan aktivasyon değerlerini daha dengeli hale getirmek için normalize eder, bu da modelin daha stabil ve hızlı öğrenmesini sağlar. <br><br>\n",
        "    •   <span style=\"font-weight: bold;\">Dropout:</span> Aşırı uyumlanmayı önlemek için eğitim sırasında bazı nöronları rastgele devre dışı bırakır, ancak test aşamasında tüm nöronlar aktiftir.<br><br>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "O9GGuZhjyx6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3># 4. İkinci Gizli Katman</h3>\n",
        "<ul style=\"background-color:#FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " İkinci Gizli Katman, İlk Gizli Katman ile aynı şekilde çalışır; ancak bu katmanda nöron sayısı 128'dir.<br><br>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "WezAGv72yx6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3># 5. Üçüncü Gizli Katman</h3>\n",
        "<ul style=\"background-color:#FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " Üçüncü Gizli Katman, İlk Gizli Katman ile aynı şekilde çalışır; ancak bu katmanda nöron sayısı 128'dir ve ayrıca Dropout işlemi uygulanmamıştır.\n",
        "<br><br>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "fHNYBtoxyx6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3># 6. Çıkış katmanı</h3>\n",
        "<ul style=\"background-color:#FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " Modelin çıkış katmanı, 9 sınıf olduğu için 9 nörondan oluşur. Çok sınıflı çıktı durumlarında \"softmax\" aktivasyon fonksiyonu kullanılır. Eğer problem ikili sınıflandırma olsaydı \"sigmoid\" kullanılırdı; regresyon problemlerinde ise \"linear\" aktivasyon tercih edilir.<br><br>\n",
        "📌 Softmax aktivasyon fonksiyonu, her sınıfa ait olasılıkları 0 ile 1 arasında normalize ederek toplamlarını 1'e eşit yapar. Bu sayede model, her sınıf için olasılık tahmininde bulunur ve en yüksek olasılığa sahip sınıfı seçerek sınıflandırma yapar..<br><br>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "RDqK5KLqyx6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> # 7. Modelin Derlenmesi</h3>\n",
        "<ul style=\"background-color:#FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " \" model.compile(...) \" fonksiyonu, modelin derlenmesini sağlar. Derleme aşaması, modelin eğitimi sırasında kullanılacak optimizasyon algoritmasını, kayıp fonksiyonunu ve değerlendirme metriklerini belirler. Şimdi bu kodun her bir parametresini detaylı bir şekilde açıklayalım:<br><br>\n",
        "        •  <span style=\"font-weight: bold;\">1. optimizer='adam'</span> Eğitim sürecinde ağırlıkların nasıl güncelleneceğini belirler. <br>Yani, Eğitim sırasında ağırlıkların ne kadar ve nasıl değişeceğini belirler. <br>Varsayılan olarak Adam (Adaptive Moment Estimation) kullanılmıştır. <br>Adam optimizasyon algoritması, eğitim sürecini hızlandırır ve daha stabil hale getirir.<br><br>\n",
        "        •  <span style=\"font-weight: bold;\">2. loss='categorical_crossentropy''</span> Loss (Kayıp) Fonksiyonu, modelin tahmin ettiği değerler ile gerçek değerler arasındaki farkı hesaplamak için kullanılır.<br>\n",
        "categorical_crossentropy, modelin çok sınıflı (multiclass) bir sınıflandırma problemi üzerinde çalıştığını gösterir.<br><br>\n",
        "            •  <span style=\"font-weight: bold;\">3. metrics=['accuracy']'</span> Metrik (Evaluation Metric), modelin performansını değerlendirmek için kullanılan metrikdir.<br><br>\n",
        "    \n",
        "<span style=\"font-weight: bold;\">accuracy:</span> Modelin tahmin ettiği sınıflardan kaç tanesinin doğru olduğunu genel olarak ölçer. Örneğin, eğer model 100 görüntüden 90'ını doğru sınıflandırdıysa doğruluğu %90 olarak değerlendirilir.<br>\n",
        "Örnek: 100 adet kedi ve köpek görüntüsünden oluşan bir veri setinde modelin %90 doğrulukla sınıflandırma yaptığını düşünelim. Bu durumda, accuracy metriği tüm sınıflar için ne kadar doğru sınıflandırma yapıldığını genel anlamda gösterir.<br><br>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "SR8dCu-Eyx6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " <span style=\"font-weight: bold;\">Diğer Değerlendirme Metrikleri: </span> <br><br>    \n",
        "    •  <span style=\"font-weight: bold;\">Precision:</span> Pozitif sınıflar için ne kadar isabetli olduğunu ölçer, yani doğru pozitif tahminlerin toplam pozitif tahminlere oranıdır.<br><br>\n",
        "    •  <span style=\"font-weight: bold;\">Recall:</span> Pozitif sınıfları ne kadar iyi yakaladığını ölçer, yani doğru pozitif tahminlerin toplam gerçek pozitif örneklere oranıdır.<br><br>     \n",
        "    •  <span style=\"font-weight: bold;\">F1 Skoru:</span> Precision ve Recall'un harmonik ortalamasıdır. Modelin genel başarısını daha dengeli bir şekilde gösterir ve özellikle dengesiz veri setlerinde tercih edilir.<br><br>\n",
        "        •  <span style=\"font-weight: bold;\">AUC-ROC (Receiver Operating Characteristic) Eğrisi:</span> Sınıflandırma problemlerinde modelin doğrulama seti üzerindeki ayırt ediciliğini ölçer. AUC (Area Under Curve), modelin sınıflar arasında ne kadar iyi ayrım yaptığını gösterir.<br><br>\n",
        "📌 Bu metrikler, modelin performansını daha detaylı ve kapsamlı bir şekilde analiz etmek için kullanılır.\n",
        "<br><br>  \n",
        "    </p>"
      ],
      "metadata": {
        "id": "WwPYP_eHyx6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a class=\"anchor\" id=\"read\"></a>\n",
        "\n",
        "## <span style=\"color:#FA8072\"> Callback Nesnelerinin Oluşturulması </span> <a class=\"anchor\" id=\"load_data\"></a>\n"
      ],
      "metadata": {
        "id": "qadQhIhqyx6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "  Callback fonksiyonları model eğitimi sırasında belirli durumlar oluştuğunda devreye girerek süreci yönetmemizi sağlayan araçlardır.<br> Örneğin, aşırı öğrenmeyi (overfitting) önlemek, eğitimi erken durdurmak veya öğrenme oranını ayarlamak gibi amaçlarla kullanılırlar.<br>\n",
        "    Bu callback'ler, her epoch tamamlandıktan sonra eğitimin iyileşmesine yönelik gerekli kontrol ve ayarlamaları yapar.\n",
        " <br>\n",
        "    </p>"
      ],
      "metadata": {
        "id": "EZqrBLEVyx6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Erken Durdurma (Early Stopping) Kullanımı\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "                               monitor='val_loss',\n",
        "                               patience=7,\n",
        "                               verbose=1,\n",
        "                               restore_best_weights=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T09:35:35.68197Z",
          "iopub.execute_input": "2024-10-24T09:35:35.682436Z",
          "iopub.status.idle": "2024-10-24T09:35:35.6902Z",
          "shell.execute_reply.started": "2024-10-24T09:35:35.682393Z",
          "shell.execute_reply": "2024-10-24T09:35:35.688833Z"
        },
        "trusted": true,
        "id": "9yBlkoE1yx6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "  Aşırı öğrenmeyi önlemek için TensorFlow Keras kütüphanesinin (tf.keras) içerisindeki callbacks modülünden EarlyStopping fonksiyonunu kullanarak <span style=\"font-weight: bold;\">early_stopping</span> isminde bir nesne oluşturuyoruz. Bu nesne, eğitim sırasında modelin doğrulama performansını izler ve iyileşme olmadığında eğitimi durdurur.<br><br>\n",
        " Girilen parametrelerin açıklamaları şu şekildedir:<br><br>\n",
        "   •  <span style=\"font-weight: bold;\">monitor='val_loss':</span> Erken durdurmanın hangi kritere göre yapılacağını belirtir. Bu durumda, doğrulama kaybı (val_loss) izlenir.<br><br>\n",
        "    📌 val_loss, doğrulama verisi için tahmin edilen değerler ile gerçek değerler arasındaki farkı ölçen bir kayıp değeridir. Bu değer, modelin doğrulama setindeki performansını gösterir.<br><br>\n",
        "       •  <span style=\"font-weight: bold;\">patience=5:</span> Doğrulama kaybı 5 epoch boyunca iyileşmezse (azalmazsa) eğitim durdurulur. Bu sayede modelin aşırı öğrenmeye başlamadan önce durdurulması amaçlanır.<br><br>\n",
        "    •  <span style=\"font-weight: bold;\">verbose=1:</span>  Erken durdurma devreye girdiğinde bilgi mesajı verir.<br><br>\n",
        "   •  <span style=\"font-weight: bold;\">restore_best_weights=True:</span> Modelin en iyi performans gösterdiği zamandaki ağırlıkları geri yükler. Böylece model, doğrulama setinde en iyi sonuç verdiği haliyle kalır.<br><br>\n",
        "    </p>"
      ],
      "metadata": {
        "id": "Z9WFdbBVyx6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Öğrenme Oranı Planlaması (Learning Rate Scheduler)\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-3 * 10**(-epoch / 20))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T09:35:36.567864Z",
          "iopub.execute_input": "2024-10-24T09:35:36.568338Z",
          "iopub.status.idle": "2024-10-24T09:35:36.574266Z",
          "shell.execute_reply.started": "2024-10-24T09:35:36.568295Z",
          "shell.execute_reply": "2024-10-24T09:35:36.572937Z"
        },
        "trusted": true,
        "id": "rrFqIaQUyx6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " Bu kodda LearningRateScheduler fonksiyonunu kullanarak <span style=\"font-weight: bold;\">lr_schedule </span> isminde bir geri çağırım (callback) nesnesi oluşturulmuştur. Bu nesne, her epoch için öğrenme oranını dinamik olarak değiştirecek şekilde ayarlanmıştır.<br><br>    \n",
        "    Kodda ki,\" lambda epoch: 1e-3 * 10**(-epoch / 20) \" kısmı, her epoch'ta öğrenme oranının nasıl güncelleneceğini belirler.<br><br>\n",
        "    •  <span style=\"font-weight: bold;\">1e-3:</span> Başlangıçta öğrenme oranı olarak 0.001 belirlenmiştir.<br><br>\n",
        "    •  <span style=\"font-weight: bold;\">10**(-epoch / 20):</span> Bu ifade, her epoch'ta öğrenme oranının üstel olarak azaltılacağını gösterir. Yani, her 20 epoch'ta öğrenme oranı 10 kat azalır. Bu, başlangıçta daha büyük adımlarla başlamak ve sonrasında daha küçük adımlarla daha hassas öğrenme yapmak için kullanılır.<br><br>\n",
        "    📌Learning Rate Scheduler aşırı öğrenmeyi önlemeye yardımcı olabilir ama esas amacı öğrenme sürecini daha verimli ve kararlı hale getirmektir.<br><br>  \n",
        "    </p>"
      ],
      "metadata": {
        "id": "8ufGXjZRyx6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a class=\"anchor\" id=\"read\"></a>\n",
        "\n",
        "## <span style=\"color:#FA8072\"> GPU Kontrolü (Grafik İşlem Birimi) </span> <a class=\"anchor\" id=\"load_data\"></a>\n"
      ],
      "metadata": {
        "id": "OSJB9Kndyx6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "📌 GPU, derin öğrenme modellerinin daha hızlı eğitilmesini sağlar.<br> Bu, özellikle büyük veri setleri ve karmaşık modellerle çalışırken eğitim süresini ciddi oranda azaltır.<br>  \n",
        "    </p>"
      ],
      "metadata": {
        "id": "1eJwyOOsyx6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()  # Mevcut bir GPU cihazı olup olmadığını kontrol eder ve varsa GPU cihazının adını döndürür.\n",
        "if \"GPU\" not in device_name:  # Eğer döndürülen cihaz adı içerisinde \"GPU\" ifadesi yoksa...\n",
        "    print(\"GPU device not found\")   # Kullanıcıya \"GPU cihazı bulunamadı\" mesajını yazdırır.\n",
        "print('Found GPU at: {}'.format(device_name))   # Eğer GPU bulunmuşsa, bulunan GPU'nun adı yazdırılır."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T09:35:37.806262Z",
          "iopub.execute_input": "2024-10-24T09:35:37.806708Z",
          "iopub.status.idle": "2024-10-24T09:35:37.814199Z",
          "shell.execute_reply.started": "2024-10-24T09:35:37.806664Z",
          "shell.execute_reply": "2024-10-24T09:35:37.812958Z"
        },
        "trusted": true,
        "id": "gr3gz4LYyx6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.is_gpu_available()  # GPU kullanılabilir mi kontrol eder, eğer varsa GPU'yu kullanarak işlemleri hızlandırır."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T09:35:38.115936Z",
          "iopub.execute_input": "2024-10-24T09:35:38.116399Z",
          "iopub.status.idle": "2024-10-24T09:35:38.124436Z",
          "shell.execute_reply.started": "2024-10-24T09:35:38.116355Z",
          "shell.execute_reply": "2024-10-24T09:35:38.123137Z"
        },
        "trusted": true,
        "id": "-sYWnNxOyx6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a class=\"anchor\" id=\"read\"></a>\n",
        "\n",
        "## <span style=\"color:#FA8072\"> Modelin Eğitilmesi (Hyperparametre Ayarlaması (RandomSearch) Öncesi): </span> <a class=\"anchor\" id=\"load_data\"></a>\n"
      ],
      "metadata": {
        "id": "amVt43VMyx6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " 📌 \"Modelin Eğitilmesi\" kodunda, modelin eğitim süreci aşağıdaki adımlarla gerçekleştiriliyor:<br><br>    \n",
        "    •  <span style=\"font-weight: bold;\">with tf.device('/GPU:0'):</span> Bu satır, TensorFlow'un GPU'yu kullanmasını sağlar. Eğer GPU mevcutsa, bu kod bloğundaki işlemler GPU üzerinde yapılacak ve bu sayede eğitim süreci hızlanacaktır.<br><br>\n",
        "    •  <span style=\"font-weight: bold;\">initial_model = create_model()</span> create_model() fonksiyonu çağrılarak initial_model isimli bir model nesnesi oluşturuluyor. Bu fonksiyon, daha önce tanımladığınız bir yapay sinir ağı modelini döndürür.<br><br>\n",
        "    •  <span style=\"font-weight: bold;\">history = initial_model.fit(...)</span> fit metodu, modelin eğitim sürecini başlatır ve aşağıdaki parametreleri kullanır:<br><br>\n",
        "    <span style=\"font-weight: bold;\">x_train:</span> Eğitim verileri.<br><br>\n",
        "    <span style=\"font-weight: bold;\">validation_data = x_val:</span> Doğrulama verileri, modelin her epoch sonundaki doğrulama performansını izlemek için kullanılır.<br><br>\n",
        "    <span style=\"font-weight: bold;\">epochs=50:</span>  Model, eğitim verileri üzerinde 50 kez tam bir geçiş yapacaktır. Yani, model verilerin tamamını 50 defa kullanarak öğrenme sürecini gerçekleştirecek.<br><br>\n",
        "    <span style=\"font-weight: bold;\">verbose=1:</span> Eğitim sırasında her epoch'un sonunda eğitim ve doğrulama metriklerini gösterir.<br><br>\n",
        "    <span style=\"font-weight: bold;\">callbacks=[lr_schedule, early_stopping]:</span> Eğitim sürecinde belirli işlemleri (erken durdurma, öğrenme oranı ayarlama) yapması için lr_schedule ve early_stopping gibi callback fonksiyonları kullanılır.<br><br>\n",
        "    </p>"
      ],
      "metadata": {
        "id": "bwEIC2_4yx6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelin Eğitilmesi (RandomSearch öncesi)\n",
        "with tf.device('/GPU:0'):\n",
        "    initial_model = create_model()\n",
        "    history = initial_model.fit(x_train,\n",
        "                                validation_data=x_val,\n",
        "                                epochs=50,\n",
        "                                verbose=1,\n",
        "                                callbacks=[lr_schedule, early_stopping])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T09:35:39.874764Z",
          "iopub.execute_input": "2024-10-24T09:35:39.875606Z",
          "iopub.status.idle": "2024-10-24T11:39:37.740585Z",
          "shell.execute_reply.started": "2024-10-24T09:35:39.875562Z",
          "shell.execute_reply": "2024-10-24T11:39:37.73755Z"
        },
        "trusted": true,
        "id": "MLZwJNqIyx6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Yardımcı Fonksiyon:\n",
        "#Bu fonksiyon (get_best_epoch_details) modelin eğitim sürecinde en düşük doğrulama kaybına (val_loss) ulaştığı\n",
        "#epoch'un (en iyi epoch) detaylarını döndürür.\n",
        "\n",
        "def get_best_epoch_details(history):\n",
        "    val_losses = history.history['val_loss']\n",
        "    min_val_loss_index = val_losses.index(min(val_losses))\n",
        "    best_epoch = min_val_loss_index + 1\n",
        "\n",
        "    epoch_details = {}\n",
        "    for key in history.history.keys():\n",
        "        epoch_details[key] = history.history[key][min_val_loss_index]\n",
        "\n",
        "    epoch_details['best_epoch'] = best_epoch\n",
        "    return epoch_details"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T11:40:05.705354Z",
          "iopub.execute_input": "2024-10-24T11:40:05.706147Z",
          "iopub.status.idle": "2024-10-24T11:40:05.721409Z",
          "shell.execute_reply.started": "2024-10-24T11:40:05.706047Z",
          "shell.execute_reply": "2024-10-24T11:40:05.720091Z"
        },
        "trusted": true,
        "id": "tg6W0WRAyx6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bu kod, eğitim sürecinde modelin en iyi performans gösterdiği(en küçük loss değeri) değeri epoch (yineleme) ile ilgili bilgileri almak\n",
        "#ve bu bilgileri ekrana yazdırmak amacıyla kullanılır.\n",
        "best_epoch_details = get_best_epoch_details(history)\n",
        "print(f\"Best epoch details: {best_epoch_details}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T11:40:06.346689Z",
          "iopub.execute_input": "2024-10-24T11:40:06.34777Z",
          "iopub.status.idle": "2024-10-24T11:40:06.354853Z",
          "shell.execute_reply.started": "2024-10-24T11:40:06.347706Z",
          "shell.execute_reply": "2024-10-24T11:40:06.353529Z"
        },
        "trusted": true,
        "id": "5cfpulrJyx6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " 📌 Görüldüğü gibi, 49. epoch en iyi sonuçları vermiş. Eğitim setinde %99.7 doğruluk ve doğrulama setinde %97.6 doğruluk elde edilmiş. Bu sonuçlar, modelin her iki veri setinde de iyi performans gösterdiğini ifade ediyor.<br><br>\n",
        "    </p>"
      ],
      "metadata": {
        "id": "RvOwCvcEyx6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Yardımcı Fonksiyon:\n",
        "#Bu fonksiyonun görevi, göstermek istediğimiz metrikleri girdiğimizde bize bu metriklerin train süreçini gösterir.\n",
        "\n",
        "def plot_training_history(history, train_loss='loss', train_metric='accuracy', val_loss='val_loss', val_metric='val_accuracy'):\n",
        "    # Loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(history.history[train_loss], label='Training Loss')\n",
        "    plt.plot(history.history[val_loss], label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # Metrics\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(history.history[train_metric], label=f\"Training: {train_metric}\")\n",
        "    plt.plot(history.history[val_metric], label=f\"Validation: {val_metric}\")\n",
        "    plt.title(f'Training and Validation {train_metric} Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(f'train_metric')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T11:40:12.427114Z",
          "iopub.execute_input": "2024-10-24T11:40:12.427616Z",
          "iopub.status.idle": "2024-10-24T11:40:12.439055Z",
          "shell.execute_reply.started": "2024-10-24T11:40:12.427565Z",
          "shell.execute_reply": "2024-10-24T11:40:12.437772Z"
        },
        "trusted": true,
        "id": "NMDM32c9yx6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelin eğitim sürecinde kaydedilen performans bilgilerini grafiksel olarak gösterir.\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T11:40:13.998523Z",
          "iopub.execute_input": "2024-10-24T11:40:13.998995Z",
          "iopub.status.idle": "2024-10-24T11:40:14.744691Z",
          "shell.execute_reply.started": "2024-10-24T11:40:13.998949Z",
          "shell.execute_reply": "2024-10-24T11:40:14.743385Z"
        },
        "trusted": true,
        "id": "oWi4Na5lyx6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " 📌 Bu grafiklerde modelin eğitim ve doğrulama süreci boyunca kayıp (loss) ve doğruluk (accuracy) değerlerinin değişimi gözlemleniyor. <br><br>\n",
        "    Eğitim ve Doğrulama Kayıpları (Training and Validation Loss Over Epochs) ve Eğitim ve Doğrulama Doğruluğu (Training and Validation Accuracy Over Epochs) grafiklerinde, bazı epochlarda  hem kayıplarda hem de doğrulukta küçük dalgalanmalar gözlemlenmektedir. Bu dalgalanmalr modelin öğrenme sürecinde yaptığı optimizasyonlardan (örneğin, batch normalization veya dropout) kaynaklanabilir ve tamamen normal bir durumdur.<br><br>\n",
        "    Epoch'lar ilerledikçe, hem eğitim hem de doğrulama setlerindeki kayıpların azaldığını ve neredeyse sabitlendiğini görüyoruz. Aynı şekilde, doğruluk (accuracy) değerleri de artıyor ve birbirine yakın seviyelerde sabitleniyor. Bu durum, modelin hem eğitim hem de doğrulama verisi üzerinde dengeli bir performans sergilediğini ve aşırı öğrenme (overfitting) yapmadığını gösteriyor. Modelin genel olarak iyi bir şekilde öğrenip genelleme yapabildiğini söyleyebiliriz.<br><br>  \n",
        "    </p>\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "LLL4cYN-yx6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = initial_model.evaluate(x_test, verbose=0)\n",
        "print('Test loss is : ',test_result[0])\n",
        "print('Test accuracy is : ',test_result[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T11:40:21.860918Z",
          "iopub.execute_input": "2024-10-24T11:40:21.861363Z",
          "iopub.status.idle": "2024-10-24T11:40:57.26408Z",
          "shell.execute_reply.started": "2024-10-24T11:40:21.861323Z",
          "shell.execute_reply": "2024-10-24T11:40:57.262824Z"
        },
        "trusted": true,
        "id": "KTMhJOpoyx6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_model.save_weights(\"my_model.weights.h5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T11:42:58.450018Z",
          "iopub.execute_input": "2024-10-24T11:42:58.450549Z",
          "iopub.status.idle": "2024-10-24T11:42:59.663418Z",
          "shell.execute_reply.started": "2024-10-24T11:42:58.450503Z",
          "shell.execute_reply": "2024-10-24T11:42:59.662243Z"
        },
        "trusted": true,
        "id": "WXGmTpwDyx6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "  Bu kod modelin test veri seti üzerindeki performansını ölçmek ve bu doğruluğu kullanıcıya göstermek için kullanılıyor. Böylece modelin test verisi üzerindeki genel performansını değerlendirebiliriz.<br><br>\n",
        "    Girilen parametrelerin açıklamaları şu şekildedir:<br><br>\n",
        "        •  <span style=\"font-weight: bold;\">initial_model nesnesi,</span>  evaluate metodunu kullanarak test verisi üzerindeki modelin performansını hesaplar ve kayıp (loss) ve doğruluk (accuracy) değerlerini döndürür.<br><br>\n",
        "        •  <span style=\"font-weight: bold;\">verbose=0 parametresi,</span> fdeğerlendirme işlemi sırasında herhangi bir ilerleme çubuğu veya detaylı çıktının ekrana yazılmasını engeller (sessiz modda çalıştırır).<br><br>\n",
        "    \" test_result \" bir liste şeklinde bir değişkendir. Bu liste, modelin test veri seti üzerindeki performansını gösteren değerleri içerir.<br><br>\n",
        "        •  <span style=\"font-weight: bold;\">test_result[0]:</span> Bu, test verisi üzerindeki kayıp (loss) değeridir. Yani modelin tahmin ettiği sonuçlar ile gerçek değerler arasındaki farkı ölçen değerdir.<br><br>\n",
        "     •  <span style=\"font-weight: bold;\">test_result[1]:</span> Bu, test verisi üzerindeki doğruluk (accuracy) değeridir. Modelin test setinde kaç tane örneği doğru tahmin ettiğini yüzdesel olarak gösterir<br><br>     \n",
        "    </p>"
      ],
      "metadata": {
        "id": "Di0i825oyx6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix ve Classification Report\n",
        "y_pred = initial_model.predict(x_test)  # Test verisi üzerindeki tahminlerin alınması\n",
        "\n",
        "y_pred_classes = np.argmax(y_pred, axis=1) # En yüksek olasılığa sahip sınıfı almak (her örnek için tahmin edilen sınıf)\n",
        "\n",
        "y_true_classes = x_test.classes  # Gerçek sınıf değerlerini almak\n",
        "\n",
        "conf_mat = confusion_matrix(y_true_classes, y_pred_classes) # Karmaşıklık matrisini oluşturmak\n",
        "\n",
        "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='d') # Karmaşıklık matrisinin görselleştirilmesi\n",
        "plt.xlabel('Predicted')  # X eksenine tahmin edilen sınıflar etiketi eklemek\n",
        "plt.ylabel('True')  # Y eksenine gerçek sınıflar etiketi eklemek\n",
        "plt.title('Confusion Matrix')   # Grafiğin başlığını eklemek\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true_classes, y_pred_classes)) # Sınıflandırma raporunu ekrana yazdırmak (precision, recall, f1-score, support)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T11:43:12.903541Z",
          "iopub.execute_input": "2024-10-24T11:43:12.904846Z",
          "iopub.status.idle": "2024-10-24T11:43:37.261274Z",
          "shell.execute_reply.started": "2024-10-24T11:43:12.904787Z",
          "shell.execute_reply": "2024-10-24T11:43:37.260173Z"
        },
        "trusted": true,
        "id": "9dTZeWG1yx6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " 📌 Confusion matrix kullanarak, modelin her sınıf için ne kadar doğru ve ne kadar yanlış tahmin yaptığını gözlemleyebiliriz. <br>Bu tablo, modelin sınıflar arasındaki performansını ayrıntılı bir şekilde anlamamıza yardımcı olur. <br>Modelimizin değerlendirme metriki olarak accuracy değerine baktığımızda, bu oran %98 olarak karşımıza çıkıyor. Bu da demek oluyor ki, modelimiz elindeki 100 balık resminden 98'ini doğru şekilde sınıflandırabilmiş. <br> Bu doğruluk oranı, modelimizin genel olarak balık türlerini büyük oranda doğru tanıdığını ve iyi bir genelleme kapasitesine sahip olduğunu gösteriyor. <br>Yani sınıflandırma görevinde etkili bir performans sergilediğini söyleyebiliriz.<br><br>    \n",
        "   📌 Precision, Recall, F1-Score değerleri de her bir sınıf için oldukça yüksektir. Bu durum, modelin her bir sınıfı doğru ve dengeli bir şekilde tahmin edebildiğini gösteriyor.<br><br>  \n",
        "    </p>"
      ],
      "metadata": {
        "id": "9r_leLkmyx6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        "<span style=\"font-weight: bold;\">Veri Setimiz Dengesiz Olsaydı, Yine Model Başarı Değerlendirme Metriği olarak Accuracy'yi Mi Kullanmalıydık? 🧐</span> <br><br>\n",
        " 📌 Burada önemli bir noktaya değinmek istiyorum. Veri setimiz dengeli, yani her sınıfın yaklaşık olarak eşit sayıda gözlem birimi var. Bu nedenle, accuracy metriği modelimizin performansını değerlendirmek için mantıklı ve yeterli bir ölçüt olarak kullanılıyor. Ancak, eğer veri setimiz dengesiz olsaydı, yani bazı sınıfların diğerlerine göre çok daha fazla ya da az sayıda olduğu bir durum olsaydı, accuracy metriği yanıltıcı olabilirdi. Çünkü çoğunluk sınıfını doğru tahmin ederek yüksek bir doğruluk elde etmek kolaydır; fakat bu durum diğer sınıfları ihmal etmek anlamına gelebilir. <br><br>  \n",
        "   📌 Bu nedenle, dengesiz veri setlerinde F1 skoru gibi metrikleri kullanmak daha uygun olacaktır. F1 skoru, precision (kesinlik) ve recall (duyarlılık) arasındaki dengeyi alarak, özellikle dengesiz sınıflar arasında daha dengeli bir performans değerlendirmesi sağlar. Böylece modelin, az temsil edilen sınıflarda da ne kadar başarılı olduğunu daha net görebiliriz.<br><br>  \n",
        "    </p>\n",
        "    "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-23T21:00:34.340408Z",
          "iopub.execute_input": "2024-10-23T21:00:34.341804Z",
          "iopub.status.idle": "2024-10-23T21:00:34.3605Z",
          "shell.execute_reply.started": "2024-10-23T21:00:34.341726Z",
          "shell.execute_reply": "2024-10-23T21:00:34.358242Z"
        },
        "id": "RZZzQ2ojyx6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a class=\"anchor\" id=\"read\"></a>\n",
        "\n",
        "## <span style=\"color:#FA8072\"> Hyperparameter Tuning (Hiperparametre Ayarlama) </span> <a class=\"anchor\" id=\"load_data\"></a>\n"
      ],
      "metadata": {
        "id": "YMdNzeAWyx6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " 📌 Hyperparameter tuning (hiperparametre ayarlama) sürecinde, modelin eğitim süresini minimize etmek amacıyla Random Search metodu kullanıldı. Random Search, hiperparametre uzayından rastgele örnekler seçerek arama yapar ve genellikle belirli bir zaman sınırlaması olduğunda veya arama uzayının çok büyük olduğu durumlarda tercih edilir. Bu metodun yerine Grid Search veya Bayesian Search gibi diğer yöntemler de kullanılabilirdi. Her bir metodun avantaj ve dezavantajlarına değinecek olursak: <br><br>  \n",
        "     •  <span style=\"font-weight: bold;\">1. Random Search:</span> Arama uzayı çok büyük olduğunda, rastgele seçimler sayesinde daha kısa sürede sonuçlara ulaşılabilir. Fakat, optimum çözüme ulaşma garantisi yoktur: Parametre uzayında sadece rastgele örnekleme yapıldığından, bazı önemli bölgeler göz ardı edilebilir ve optimum çözüme ulaşamayabilir.<br><br>\n",
        "     •  <span style=\"font-weight: bold;\">2. Grid Search:</span> Belirlenen hiperparametre kombinasyonlarının tamamı taranır ve bu sayede optimum sonuca ulaşma olasılığı yüksektir. Fakat, arama uzayı büyükse, deneme sayısı katlanarak artar ve bu da çok fazla zaman ve hesaplama gücü gerektirir.<br><br>\n",
        "         •  <span style=\"font-weight: bold;\">3. Bayesian Optimization:</span> Önceki denemelerden elde edilen sonuçlara dayalı olarak hiperparametre aramasını optimize eder ve böylece daha az denemeyle iyi sonuçlara ulaşabilir. Bu yöntem, Grid Search'e kıyasla daha az denemeyle iyi sonuçlara ulaşmayı sağlar ve özellikle arama uzayı büyük olduğunda zamandan tasarruf edebilir. Ancak, yine de çok büyük arama uzaylarında denemeler uzun sürebilir ve bu da yüksek hesaplama gücü gerektirebilir.<br><br>     \n",
        "    ✅Yapmış olduğum Random Search ile yapılan hiperparametre aramalarında modelde belirgin bir iyileşme gözlenmemiştir. Bu durum, Random Search'ün beklenen bir sonucudur, çünkü bu yöntem genellikle arama uzayını rastgele taradığı için en iyi hiperparametre kombinasyonunu bulmak her zaman garanti değildir.<br><br>   \n",
        "    </p>"
      ],
      "metadata": {
        "id": "F0ECeQ5xyx6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparametre optimizasyonu için modelin oluşturulması\n",
        "# Bu fonksiyon, belirli hiperparametrelerle bir model oluşturur ve modelin çeşitli yapılandırma seçeneklerini test eder.\n",
        "# Hyperparameter tuning sırasında kullanılır ve modelin performansını en üst düzeye çıkarmak amaçlanır.\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Rescaling layer: Giriş verilerini normalleştirir ve 0-1 aralığına getirir.\n",
        "    model.add(Rescaling(1./255))\n",
        "\n",
        "    # Flatten layer: Giriş verilerini tek boyutlu bir vektöre dönüştürerek gizli katmanlara aktarır.\n",
        "    model.add(Flatten(input_shape=(224, 224, 3)))\n",
        "\n",
        "    # Hidden layers: Belirli hiperparametrelere göre değişen nöron sayısı, aktivasyon fonksiyonu, regularizasyon ve dropout ile gizli katmanlar oluşturur.\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        model.add(#Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=256, step=32),\n",
        "                  Dense(units=hp.Choice('units_' + str(i), values=[64, 128]),\n",
        "                        activation=hp.Choice('activation_' + str(i), values=['relu', 'leaky_relu']),\n",
        "                        kernel_regularizer=l2(hp.Float('l2_' + str(i), min_value=0.0001, max_value=0.01, sampling='log'))))\n",
        "        model.add(BatchNormalization()) # Batch Normalization, aktivasyon sonucu elde edilen değerleri normalize eder\n",
        "        model.add(Dropout(hp.Float('dropout_' + str(i), min_value=0.1, max_value=0.5, step=0.1))) # Dropout, bazı nöronları rastgele devre dışı bırakır\n",
        "\n",
        "    # Output layer: Modelin sınıflandırma sonucunu (9 sınıf) üretir.\n",
        "    model.add(Dense(9, activation='softmax'))\n",
        "\n",
        "    # Learning rate schedule: Öğrenme oranını zamanla azaltarak daha etkili ve kararlı bir eğitim sağlar.\n",
        "    initial_learning_rate = hp.Float('initial_learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "    lr_schedule = ExponentialDecay(\n",
        "        initial_learning_rate=initial_learning_rate,\n",
        "        decay_steps=1000,\n",
        "        decay_rate=0.96,\n",
        "        staircase=True\n",
        "    )\n",
        "\n",
        "    # Optimizer selection: SGD veya Adam gibi optimizasyon algoritmalarını seçer ve bu algoritmalara özgü hiperparametreleri ayarlar.\n",
        "    optimizer_choice = hp.Choice('optimizer', values=['sgd', 'adam'])\n",
        "    if optimizer_choice == 'sgd':\n",
        "        optimizer = SGD(\n",
        "            learning_rate=lr_schedule,\n",
        "            momentum=hp.Float('momentum', min_value=0.0, max_value=0.9, step=0.1)\n",
        "        )\n",
        "    elif optimizer_choice == 'adam':\n",
        "        optimizer = Adam(\n",
        "            learning_rate=lr_schedule,\n",
        "            beta_1=hp.Float('beta1', min_value=0.85, max_value=0.99, step=0.01),\n",
        "            beta_2=hp.Float('beta2', min_value=0.999, max_value=0.9999, step=0.0001),\n",
        "            epsilon=hp.Float('epsilon', min_value=1e-8, max_value=1e-7, step=1e-8)\n",
        "        )\n",
        "\n",
        "    # Model compilation: Modeli derler ve öğrenme sürecinde kullanılacak kayıp fonksiyonu ve metrikleri belirler.\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T11:47:32.01321Z",
          "iopub.execute_input": "2024-10-24T11:47:32.014351Z",
          "iopub.status.idle": "2024-10-24T11:47:32.031672Z",
          "shell.execute_reply.started": "2024-10-24T11:47:32.014299Z",
          "shell.execute_reply": "2024-10-24T11:47:32.030588Z"
        },
        "trusted": true,
        "id": "nZ_Ls0z-yx6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search_tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=2,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True)\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T11:47:35.327062Z",
          "iopub.execute_input": "2024-10-24T11:47:35.327495Z",
          "iopub.status.idle": "2024-10-24T11:47:35.361284Z",
          "shell.execute_reply.started": "2024-10-24T11:47:35.327455Z",
          "shell.execute_reply": "2024-10-24T11:47:35.36022Z"
        },
        "trusted": true,
        "id": "pNjAWZcZyx6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using GPU for training\n",
        "with tf.device('/GPU:0'):\n",
        "    random_search_tuner.search(x_train,\n",
        "                               epochs=50,\n",
        "                               validation_data=x_val,\n",
        "                               callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T11:47:35.933975Z",
          "iopub.execute_input": "2024-10-24T11:47:35.935019Z",
          "iopub.status.idle": "2024-10-24T12:42:21.298313Z",
          "shell.execute_reply.started": "2024-10-24T11:47:35.934963Z",
          "shell.execute_reply": "2024-10-24T12:42:21.297093Z"
        },
        "trusted": true,
        "id": "QXMyooXCyx6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = random_search_tuner.get_best_hyperparameters(num_trials=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:42:21.300993Z",
          "iopub.execute_input": "2024-10-24T12:42:21.301521Z",
          "iopub.status.idle": "2024-10-24T12:42:21.307126Z",
          "shell.execute_reply.started": "2024-10-24T12:42:21.301464Z",
          "shell.execute_reply": "2024-10-24T12:42:21.306083Z"
        },
        "trusted": true,
        "id": "4jy2pTpPyx6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps_1 = best_hps[0]\n",
        "best_hps_2 = best_hps[1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:42:21.308521Z",
          "iopub.execute_input": "2024-10-24T12:42:21.308904Z",
          "iopub.status.idle": "2024-10-24T12:42:21.330088Z",
          "shell.execute_reply.started": "2024-10-24T12:42:21.308864Z",
          "shell.execute_reply": "2024-10-24T12:42:21.328807Z"
        },
        "trusted": true,
        "id": "tbrSRht-yx6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best hyperparameters: {best_hps_1.values}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:42:21.333191Z",
          "iopub.execute_input": "2024-10-24T12:42:21.33372Z",
          "iopub.status.idle": "2024-10-24T12:42:21.341999Z",
          "shell.execute_reply.started": "2024-10-24T12:42:21.333664Z",
          "shell.execute_reply": "2024-10-24T12:42:21.340784Z"
        },
        "trusted": true,
        "id": "4pUUbHvYyx6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best hyperparameters: {best_hps_2.values}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:42:21.343335Z",
          "iopub.execute_input": "2024-10-24T12:42:21.343742Z",
          "iopub.status.idle": "2024-10-24T12:42:21.353445Z",
          "shell.execute_reply.started": "2024-10-24T12:42:21.343688Z",
          "shell.execute_reply": "2024-10-24T12:42:21.352093Z"
        },
        "trusted": true,
        "id": "4PUkoWF4yx6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = random_search_tuner.get_best_models(num_models=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:42:21.354626Z",
          "iopub.execute_input": "2024-10-24T12:42:21.355034Z",
          "iopub.status.idle": "2024-10-24T12:42:23.055394Z",
          "shell.execute_reply.started": "2024-10-24T12:42:21.354994Z",
          "shell.execute_reply": "2024-10-24T12:42:23.054438Z"
        },
        "trusted": true,
        "id": "yLU1wRl-yx6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, model in enumerate(best_models):\n",
        "    loss, acc = model.evaluate(x_test, verbose=0)\n",
        "    print(f\"Model {i+1}, Validation loss: {loss}, Validation Accuracy: {acc}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:42:23.057153Z",
          "iopub.execute_input": "2024-10-24T12:42:23.057519Z",
          "iopub.status.idle": "2024-10-24T12:43:12.917327Z",
          "shell.execute_reply.started": "2024-10-24T12:42:23.05748Z",
          "shell.execute_reply": "2024-10-24T12:43:12.91622Z"
        },
        "trusted": true,
        "id": "1g7JFIEXyx6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " 📌 Görüldüğü üzere, Random Search ile yapılan hiperparametre optimizasyonu sonucunda iki model üzerinde belirgin bir iyileşme gözlenememiştir: <br><br>  \n",
        "     •  Model 1: Validation loss: 0.7093, Validation Accuracy: %86.33<br><br>\n",
        "     • Model 2: Validation loss: 1.4009, Validation Accuracy: %69.11<br><br>      \n",
        "    ✅Bu sonuçlar doğrultusunda, hiperparametre optimizasyonu yapmadan mevcut modelimizle devam ettik ve eğitim setindeki sınıfları tahmin etmeye odaklandık. Modelimiz mevcut haliyle test setinde iyi bir performans sergileyerek yüksek doğruluk oranına ulaşmıştır.<br><br>   \n",
        "    ✅ Ayrıca, hiperparametre optimizasyonunda arama uzayını dar tutmak zorunda kaldık. Bunun nedeni, GPU limitlerimize ulaştığımız için daha uzun süren deneyler yapmanın mümkün olmamasıydı. Bu kısıtlamalar nedeniyle, daha geniş bir arama yapamamış olsak da, model mevcut haliyle tatmin edici sonuçlar vermeye devam etmektedir.\n",
        "    </p>"
      ],
      "metadata": {
        "id": "NHwYkrbByx6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FINAL MODEL"
      ],
      "metadata": {
        "id": "d6_wW16zyx6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"background-color: #FFDAB9; padding: 15px; border-radius: 10px;\">\n",
        " 📌 Bu bölümde, nihai model test edilmiştir.<br>   </p>"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T13:07:46.72918Z",
          "iopub.execute_input": "2024-10-24T13:07:46.730034Z",
          "iopub.status.idle": "2024-10-24T13:07:46.737473Z",
          "shell.execute_reply.started": "2024-10-24T13:07:46.729972Z",
          "shell.execute_reply": "2024-10-24T13:07:46.735808Z"
        },
        "id": "Q0x9sNVZyx6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_model.load_weights('my_model.weights.h5')  # Kaydedilen ağırlıkları yüklüyoruz"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:54:12.740675Z",
          "iopub.execute_input": "2024-10-24T12:54:12.741192Z",
          "iopub.status.idle": "2024-10-24T12:54:13.77138Z",
          "shell.execute_reply.started": "2024-10-24T12:54:12.741144Z",
          "shell.execute_reply": "2024-10-24T12:54:13.770051Z"
        },
        "trusted": true,
        "id": "afZAjov_yx6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_model.summary()  # Modelin özetini (katman yapısını) yazdırıyoruz"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:54:17.132936Z",
          "iopub.execute_input": "2024-10-24T12:54:17.133423Z",
          "iopub.status.idle": "2024-10-24T12:54:17.174932Z",
          "shell.execute_reply.started": "2024-10-24T12:54:17.133376Z",
          "shell.execute_reply": "2024-10-24T12:54:17.173657Z"
        },
        "trusted": true,
        "id": "VzV8ugFHyx6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = initial_model.evaluate(x_test, verbose=0)\n",
        "print('Test loss is : ',test_result[0])\n",
        "print('Test accuracy is : ',test_result[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:47:51.239171Z",
          "iopub.execute_input": "2024-10-24T12:47:51.23966Z",
          "iopub.status.idle": "2024-10-24T12:48:14.666081Z",
          "shell.execute_reply.started": "2024-10-24T12:47:51.239617Z",
          "shell.execute_reply": "2024-10-24T12:48:14.664825Z"
        },
        "trusted": true,
        "id": "N7iTFphFyx6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix ve Classification Report\n",
        "y_pred = initial_model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = x_test.classes\n",
        "\n",
        "conf_mat = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true_classes, y_pred_classes))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:54:24.195087Z",
          "iopub.execute_input": "2024-10-24T12:54:24.195969Z",
          "iopub.status.idle": "2024-10-24T12:54:48.360984Z",
          "shell.execute_reply.started": "2024-10-24T12:54:24.19592Z",
          "shell.execute_reply": "2024-10-24T12:54:48.359813Z"
        },
        "trusted": true,
        "id": "z9_IBLSByx6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test verisini kopyalayıp predict_data adında yeni bir DataFrame oluşturuyoruz.\n",
        "predict_data = test_data.copy()\n",
        "\n",
        "# Boş bir labels sözlüğü tanımlıyoruz.\n",
        "labels={}\n",
        "\n",
        "# Mevcut sınıf indekslerini tersine çevirerek (indeks -> sınıf etiketi) labels sözlüğüne ekliyoruz.\n",
        "for l,v in x_test.class_indices.items():\n",
        "    labels.update({v:l})\n",
        "\n",
        "# Modelin tahmin ettiği sınıf indekslerini 'pred' adlı bir sütuna atıyoruz.\n",
        "predict_data['pred'] = y_pred_classes\n",
        "\n",
        "# Tahmin edilen sınıf indekslerini sınıf etiketlerine çeviriyoruz.\n",
        "predict_data['pred'] = predict_data['pred'].apply(lambda x: labels[x])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:54:48.36318Z",
          "iopub.execute_input": "2024-10-24T12:54:48.363546Z",
          "iopub.status.idle": "2024-10-24T12:54:48.378829Z",
          "shell.execute_reply.started": "2024-10-24T12:54:48.363507Z",
          "shell.execute_reply": "2024-10-24T12:54:48.377544Z"
        },
        "trusted": true,
        "id": "eYotBDodyx6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame'in indekslerini sıfırlıyoruz, eski indeksleri korumadan (drop=True) yeni bir sıralı indeks oluşturuyoruz.\n",
        "predict_data = predict_data.reset_index(drop=True)\n",
        "\n",
        "# İlk 10 satırı görüntülüyoruz, tahmin edilen sonuçları kontrol etmek için.\n",
        "predict_data.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:54:48.380391Z",
          "iopub.execute_input": "2024-10-24T12:54:48.380912Z",
          "iopub.status.idle": "2024-10-24T12:54:48.406358Z",
          "shell.execute_reply.started": "2024-10-24T12:54:48.380857Z",
          "shell.execute_reply": "2024-10-24T12:54:48.405119Z"
        },
        "trusted": true,
        "id": "GhY9CWnSyx6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerçek etiketler ('label') ile tahmin edilen etiketler ('pred') eşleşmeyen satırları filtreleyip gösteriyoruz.\n",
        "# Bu sayede modelin yanlış sınıflandırdığı verileri görebiliriz.\n",
        "\n",
        "predict_data[predict_data['label']!=predict_data['pred']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T12:54:48.408768Z",
          "iopub.execute_input": "2024-10-24T12:54:48.409174Z",
          "iopub.status.idle": "2024-10-24T12:54:48.431767Z",
          "shell.execute_reply.started": "2024-10-24T12:54:48.409132Z",
          "shell.execute_reply": "2024-10-24T12:54:48.430449Z"
        },
        "trusted": true,
        "id": "P39lo0L3yx6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelinin tahmin sonuçlarını görselleştirmek ve karşılaştırmak için kullanılır.\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(plt.imread(predict_data.path[14]))\n",
        "title1 = predict_data.path[14].split('/')[-2]\n",
        "title2 = predict_data.path[14].split('/')[-1]\n",
        "title3 = predict_data.pred[14]\n",
        "plt.title(f'Image:- {title2}\\nTrue Class:- {title1}\\nPredicted Class:- {title3}', color = 'r', weight = 'bold', fontsize = 15)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-24T13:36:11.602569Z",
          "iopub.execute_input": "2024-10-24T13:36:11.603145Z",
          "iopub.status.idle": "2024-10-24T13:36:13.529411Z",
          "shell.execute_reply.started": "2024-10-24T13:36:11.603098Z",
          "shell.execute_reply": "2024-10-24T13:36:13.527628Z"
        },
        "trusted": true,
        "id": "YEQjftuZyx6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9XhVWePeyx6x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}